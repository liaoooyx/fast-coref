{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52566bc8-8fa5-4348-b0d9-9979460c4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d6b3cf-1877-4194-82d1-0a253fe9bf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f19f0e7-2135-477f-8a0c-a3ac5e27f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "os.path.abspath(\"./\")\n",
    "sys.path.append(os.path.abspath(\"/scratch/c.c21051562/workspace/fast-coref/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e07f4c-1272-4321-bdef-7ef41a35f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50400\n"
     ]
    }
   ],
   "source": [
    "print(14*3600) # Jupyter Notebook/Lab (51629639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4981dfbb-0020-4a02-bcfd-897e02203ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-04 23:08:21'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9524e4c8-dbf6-4b58-99e7-58d171b32038",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/c.c21051562/workspace/fast-coref/src/main.py:132: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "[2023-01-04 23:08:23,572][HYDRA] Hydra 1.2.0\n",
      "[2023-01-04 23:08:23,572][HYDRA] ===========\n",
      "[2023-01-04 23:08:23,572][HYDRA] Installed Hydra Plugins\n",
      "[2023-01-04 23:08:23,572][HYDRA] ***********************\n",
      "[2023-01-04 23:08:23,572][HYDRA] \tConfigSource:\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t-------------\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tFileConfigSource\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tImportlibResourcesConfigSource\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tStructuredConfigSource\n",
      "[2023-01-04 23:08:23,572][HYDRA] \tCompletionPlugin:\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t-----------------\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tBashCompletion\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tFishCompletion\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tZshCompletion\n",
      "[2023-01-04 23:08:23,572][HYDRA] \tLauncher:\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t---------\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tBasicLauncher\n",
      "[2023-01-04 23:08:23,572][HYDRA] \tSweeper:\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t--------\n",
      "[2023-01-04 23:08:23,572][HYDRA] \t\tBasicSweeper\n",
      "[2023-01-04 23:08:23,572][HYDRA] \n",
      "[2023-01-04 23:08:23,572][HYDRA] Config search path\n",
      "[2023-01-04 23:08:23,572][HYDRA] ******************\n",
      "[2023-01-04 23:08:23,705][HYDRA] | Provider | Search path                                               |\n",
      "[2023-01-04 23:08:23,705][HYDRA] ------------------------------------------------------------------------\n",
      "[2023-01-04 23:08:23,705][HYDRA] | hydra    | pkg://hydra.conf                                          |\n",
      "[2023-01-04 23:08:23,705][HYDRA] | main     | file:///scratch/c.c21051562/workspace/fast-coref/src/conf |\n",
      "[2023-01-04 23:08:23,705][HYDRA] | schema   | structured://                                             |\n",
      "[2023-01-04 23:08:23,705][HYDRA] ------------------------------------------------------------------------\n",
      "[2023-01-04 23:08:23,789][HYDRA] \n",
      "[2023-01-04 23:08:23,789][HYDRA] Defaults Tree\n",
      "[2023-01-04 23:08:23,789][HYDRA] *************\n",
      "[2023-01-04 23:08:23,789][HYDRA] <root>:\n",
      "[2023-01-04 23:08:23,789][HYDRA]   hydra/config:\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/output: default\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/launcher: basic\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/sweeper: basic\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/help: default\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/hydra_help: default\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/hydra_logging: default\n",
      "[2023-01-04 23:08:23,789][HYDRA]     hydra/job_logging: none\n",
      "[2023-01-04 23:08:23,790][HYDRA]     hydra/callbacks: null\n",
      "[2023-01-04 23:08:23,790][HYDRA]     hydra/env: default\n",
      "[2023-01-04 23:08:23,790][HYDRA]     _self_\n",
      "[2023-01-04 23:08:23,790][HYDRA]   config:\n",
      "[2023-01-04 23:08:23,790][HYDRA]     _self_\n",
      "[2023-01-04 23:08:23,790][HYDRA]     datasets: mimic_manual_500_unsplit\n",
      "[2023-01-04 23:08:23,790][HYDRA]     model: model:\n",
      "[2023-01-04 23:08:23,790][HYDRA]       model/doc_encoder: transformer_encoder:\n",
      "[2023-01-04 23:08:23,790][HYDRA]         model/doc_encoder/transformer: longformer_joint_arcca_local\n",
      "[2023-01-04 23:08:23,790][HYDRA]         model/_self_\n",
      "[2023-01-04 23:08:23,790][HYDRA]       model/memory: memory:\n",
      "[2023-01-04 23:08:23,790][HYDRA]         model/memory/mem_type: unbounded\n",
      "[2023-01-04 23:08:23,790][HYDRA]         model/_self_\n",
      "[2023-01-04 23:08:23,790][HYDRA]       _self_\n",
      "[2023-01-04 23:08:23,790][HYDRA]     optimizer: adam\n",
      "[2023-01-04 23:08:23,790][HYDRA]     trainer: train.yaml\n",
      "[2023-01-04 23:08:23,790][HYDRA]     infra: arcca\n",
      "[2023-01-04 23:08:23,790][HYDRA]     experiment: arcca_exp_9\n",
      "[2023-01-04 23:08:23,873][HYDRA] \n",
      "[2023-01-04 23:08:23,873][HYDRA] Defaults List\n",
      "[2023-01-04 23:08:23,873][HYDRA] *************\n",
      "[2023-01-04 23:08:23,873][HYDRA] | Config path                                                | Package                       | _self_ | Parent                                | \n",
      "[2023-01-04 23:08:23,873][HYDRA] ------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[2023-01-04 23:08:23,873][HYDRA] | hydra/output/default                                       | hydra                         | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,873][HYDRA] | hydra/launcher/basic                                       | hydra.launcher                | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/sweeper/basic                                        | hydra.sweeper                 | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/help/default                                         | hydra.help                    | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/hydra_help/default                                   | hydra.hydra_help              | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/hydra_logging/default                                | hydra.hydra_logging           | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/job_logging/none                                     | hydra.job_logging             | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/env/default                                          | hydra.env                     | False  | hydra/config                          |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | hydra/config                                               | hydra                         | True   | <root>                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | config                                                     |                               | True   | <root>                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | datasets/mimic_manual_500_unsplit                          | datasets                      | False  | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | model/doc_encoder/transformer/longformer_joint_arcca_local | model.doc_encoder.transformer | False  | model/doc_encoder/transformer_encoder |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | model/doc_encoder/transformer_encoder                      | model.doc_encoder             | True   | model/model                           |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | model/memory/mem_type/unbounded                            | model.memory.mem_type         | False  | model/memory/memory                   |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | model/memory/memory                                        | model.memory                  | True   | model/model                           |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | model/model                                                | model                         | True   | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | optimizer/adam                                             | optimizer                     | False  | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | trainer/train.yaml                                         | trainer                       | False  | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | infra/arcca                                                | infra                         | False  | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] | experiment/arcca_exp_9                                     |                               | False  | config                                |\n",
      "[2023-01-04 23:08:23,874][HYDRA] ------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[2023-01-04 23:08:23,997][HYDRA] Config\n",
      "[2023-01-04 23:08:23,997][HYDRA] ******\n",
      "[2023-01-04 23:08:24,003][HYDRA] metrics:\n",
      "- MUC\n",
      "- Bcub\n",
      "- CEAFE\n",
      "keep_singletons: false\n",
      "seed: 45\n",
      "train: true\n",
      "use_wandb: false\n",
      "override_encoder: true\n",
      "override_memory: false\n",
      "copy_from_pretrained_model: true\n",
      "continue_training: false\n",
      "paths:\n",
      "  resource_dir: ${infra.project_dir}/coref_resources\n",
      "  base_data_dir: ${paths.resource_dir}/data\n",
      "  conll_scorer: ${paths.resource_dir}/reference-coreference-scorers/scorer.pl\n",
      "  base_model_dir: ${infra.project_dir}/models\n",
      "  model_dir: null\n",
      "  best_model_dir: null\n",
      "  model_filename: model.pth\n",
      "  model_name: model_904_10_2\n",
      "  model_name_prefix: coref_\n",
      "  model_path: null\n",
      "  best_model_path: null\n",
      "  doc_encoder_dirname: doc_encoder\n",
      "  pretrain_model_dir: /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best\n",
      "datasets:\n",
      "  mimic_manual_500_unsplit:\n",
      "    name: mimic_manual_500_unsplit\n",
      "    cluster_threshold: 2\n",
      "    canonical_cluster_threshold: 2\n",
      "    targeted_eval: false\n",
      "    num_train_docs: 10\n",
      "    num_dev_docs: 1\n",
      "    num_test_docs: 156\n",
      "    has_conll: true\n",
      "    singleton_file: null\n",
      "model:\n",
      "  doc_encoder:\n",
      "    transformer:\n",
      "      name: longformer\n",
      "      model_size: large\n",
      "      model_str: /scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint\n",
      "      max_encoder_segment_len: 4096\n",
      "      max_segment_len: 4096\n",
      "    chunking: independent\n",
      "    finetune: false\n",
      "    add_speaker_tokens: true\n",
      "    speaker_start: '[SPEAKER_START]'\n",
      "    speaker_end: '[SPEAKER_END]'\n",
      "  memory:\n",
      "    mem_type:\n",
      "      name: unbounded\n",
      "      max_ents: null\n",
      "      eval_max_ents: null\n",
      "    emb_size: 20\n",
      "    mlp_size: 3000\n",
      "    mlp_depth: 1\n",
      "    sim_func: hadamard\n",
      "    entity_rep: wt_avg\n",
      "    num_feats: 2\n",
      "  mention_params:\n",
      "    max_span_width: 20\n",
      "    ment_emb: attn\n",
      "    use_gold_ments: false\n",
      "    use_topk: false\n",
      "    top_span_ratio: 0.4\n",
      "    emb_size: 20\n",
      "    mlp_size: 3000\n",
      "    mlp_depth: 1\n",
      "    ment_emb_to_size_factor:\n",
      "      attn: 3\n",
      "      endpoint: 2\n",
      "      max: 1\n",
      "  metadata_params:\n",
      "    use_genre_feature: false\n",
      "    default_genre: nw\n",
      "    genres:\n",
      "    - bc\n",
      "    - bn\n",
      "    - mz\n",
      "    - nw\n",
      "    - pt\n",
      "    - tc\n",
      "    - wb\n",
      "optimizer:\n",
      "  init_lr: 0.0003\n",
      "  fine_tune_lr: 1.0e-05\n",
      "  max_gradient_norm: 1.0\n",
      "  lr_decay: linear\n",
      "trainer:\n",
      "  dropout_rate: 0.3\n",
      "  label_smoothing_wt: 0.1\n",
      "  ment_loss: all\n",
      "  normalize_loss: false\n",
      "  max_evals: 100\n",
      "  to_save_model: true\n",
      "  log_frequency: 50\n",
      "  patience: 10\n",
      "  eval_per_k_steps: 10\n",
      "  num_training_steps: null\n",
      "  max_training_segments: 1\n",
      "infra:\n",
      "  is_local: false\n",
      "  job_time: 54000\n",
      "  job_id: 904102\n",
      "  project_dir: /scratch/c.c21051562/workspace/fast-coref\n",
      "  work_dir: ${project_dir}/src/\n",
      "\n",
      "/home/c.c21051562/.conda/envs/fast_coref/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-01-04 23:08:24,040][HYDRA] Configuration process\n",
      "[2023-01-04 23:08:24,040][HYDRA] Set up configurartion for training\n",
      "[2023-01-04 23:08:24,041][HYDRA] Original paths config:{'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': None, 'best_model_dir': None, 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': None, 'best_model_path': None, 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}\n",
      "[2023-01-04 23:08:24,060][HYDRA] Copying the pretrained model from [/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best]\n",
      "[2023-01-04 23:08:24,476][HYDRA] Copied /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best/model.pth -> /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth\n",
      "[2023-01-04 23:08:24,478][HYDRA] Rewrote paths config:{'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}\n",
      "[2023-01-04 23:08:24,479][HYDRA] Start experiment. Model name: model_904_10_2\n",
      "[2023-01-04 23:08:24,479][HYDRA] Initial for training\n",
      "[2023-01-04 23:08:24,479][HYDRA] Step 1 - Initialize the EntityRankingModel\n",
      "[2023-01-04 23:08:24,479][HYDRA] model_params:{'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}\n",
      "[2023-01-04 23:08:24,479][HYDRA] train_config:{'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': None, 'max_training_segments': 1}\n",
      "mention_proposer.span_width_embeddings.weight torch.Size([20, 20])\n",
      "mention_proposer.span_width_prior_embeddings.weight torch.Size([20, 20])\n",
      "mention_proposer.mention_attn.weight torch.Size([1, 1024])\n",
      "mention_proposer.mention_attn.bias torch.Size([1])\n",
      "mention_proposer.mention_mlp.fc_layers.0.weight torch.Size([3000, 3092])\n",
      "mention_proposer.mention_mlp.fc_layers.0.bias torch.Size([3000])\n",
      "mention_proposer.mention_mlp.fc_layers.3.weight torch.Size([1, 3000])\n",
      "mention_proposer.mention_mlp.fc_layers.3.bias torch.Size([1])\n",
      "mention_proposer.span_width_mlp.fc_layers.0.weight torch.Size([3000, 20])\n",
      "mention_proposer.span_width_mlp.fc_layers.0.bias torch.Size([3000])\n",
      "mention_proposer.span_width_mlp.fc_layers.3.weight torch.Size([1, 3000])\n",
      "mention_proposer.span_width_mlp.fc_layers.3.bias torch.Size([1])\n",
      "memory_net.mem_coref_mlp.fc_layers.0.weight torch.Size([3000, 9316])\n",
      "memory_net.mem_coref_mlp.fc_layers.0.bias torch.Size([3000])\n",
      "memory_net.mem_coref_mlp.fc_layers.3.weight torch.Size([1, 3000])\n",
      "memory_net.mem_coref_mlp.fc_layers.3.bias torch.Size([1])\n",
      "memory_net.distance_embeddings.weight torch.Size([10, 20])\n",
      "memory_net.counter_embeddings.weight torch.Size([10, 20])\n",
      "\n",
      "Total Params:37.30 (in millions)\n",
      "[2023-01-04 23:08:37,358][HYDRA] Step 2 - Load Data - Data processing choices such as tokenizer will depend on the model\n",
      "[2023-01-04 23:08:37,424][HYDRA] --self.config.paths.base_data_dir:/scratch/c.c21051562/workspace/fast-coref/coref_resources/data\n",
      "[2023-01-04 23:08:37,425][HYDRA] Data directory: /scratch/c.c21051562/workspace/fast-coref/coref_resources/data/mimic_manual_500_unsplit/longformer\n",
      "[2023-01-04 23:08:37,493][HYDRA] Number of training steps: 1000\n",
      "[2023-01-04 23:08:37,493][HYDRA] Step 3 - Resume training\n",
      "[2023-01-04 23:08:37,493][HYDRA] Initialize optimizers\n",
      "[2023-01-04 23:08:37,493][HYDRA] optimizer_config:{'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}\n",
      "[2023-01-04 23:08:37,493][HYDRA] train_config:{'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}\n",
      "[2023-01-04 23:08:37,494][HYDRA] self.scaler:<torch.cuda.amp.grad_scaler.GradScaler object at 0x2b6e931982e0>\n",
      "[2023-01-04 23:08:37,495][HYDRA] self.optimizer:{'mem': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-06\n",
      "    foreach: None\n",
      "    initial_lr: 0.0003\n",
      "    lr: 0.0003\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")}\n",
      "[2023-01-04 23:08:37,495][HYDRA] self.optim_scheduler:{'mem': <torch.optim.lr_scheduler.LambdaLR object at 0x2b6e48eee790>}\n",
      "[2023-01-04 23:08:37,496][HYDRA] Step 4 - Loading the checkpoint also restores the training metadata\n",
      "[2023-01-04 23:08:37,496][HYDRA] Resume training model from the best checkpoint\n",
      "[2023-01-04 23:08:37,496][HYDRA] Load checkpoint from: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth, last_checkpoint:[False]\n",
      "[2023-01-04 23:08:37,576][HYDRA] Loading model from /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth\n",
      "[2023-01-04 23:08:37,576][HYDRA] Original self.config:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': True, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}, 'datasets': {'mimic_manual_500_unsplit': {'name': 'mimic_manual_500_unsplit', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 10, 'num_dev_docs': 1, 'num_test_docs': 156, 'has_conll': True, 'singleton_file': None}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 54000, 'job_id': 904102, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:08:37,576][HYDRA] checkpoint['config']:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': False, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2/best', 'model_filename': 'model.pth', 'model_name': 'joint_train_onto_i2b2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '${paths.base_model_dir}/joint_best'}, 'datasets': {'ontonotes': {'name': 'OntoNotes', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 2802, 'num_dev_docs': 343, 'num_test_docs': 348, 'has_conll': True, 'singleton_file': None}, 'i2b2': {'name': 'i2b2', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'cross_val_split': 0, 'targeted_eval': False, 'num_train_docs': 296, 'num_dev_docs': 84, 'num_test_docs': 44, 'has_conll': True}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 20, 'to_save_model': True, 'log_frequency': 300, 'patience': 10, 'eval_per_k_steps': 3098, 'num_training_steps': 61960, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 72000, 'job_id': 310, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:08:37,576][HYDRA] This is fine-tuning mode, we merge self.config with checkpoint['config']\n",
      "[2023-01-04 23:08:37,582][HYDRA] New self.config:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': True, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}, 'datasets': {'mimic_manual_500_unsplit': {'name': 'mimic_manual_500_unsplit', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 10, 'num_dev_docs': 1, 'num_test_docs': 156, 'has_conll': True, 'singleton_file': None}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 54000, 'job_id': 904102, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:08:37,610][HYDRA] Model loaded\n",
      "\n",
      "[2023-01-04 23:08:37,611][HYDRA] Now in the method of model training\n",
      "[2023-01-04 23:08:37,612][HYDRA] Steps done 0\n",
      "[2023-01-04 23:08:37,612][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:37,612][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:39,353][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:39,355][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:39,475][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:39,477][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:39,477][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:39,478][HYDRA] Inference time: 0.12\n",
      "[2023-01-04 23:08:39,478][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:39,478][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:39,478][HYDRA] F1: 22.2, Max F1: 0.0\n",
      "[2023-01-04 23:08:39,478][HYDRA] Saving best model\n",
      "[2023-01-04 23:08:39,478][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth, last_checkpoint:[False]\n",
      "[2023-01-04 23:08:39,910][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth\n",
      "[2023-01-04 23:08:39,911][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:39,917][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:41,106][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:41,109][HYDRA] Steps: 10, F1: 22.2, Max F1: 22.2, Time: 3.50\n",
      "[2023-01-04 23:08:41,109][HYDRA] Average eval time: 0.06 mins, Remaining time: 899.94 mins\n",
      "[2023-01-04 23:08:41,109][HYDRA] Steps done 10\n",
      "[2023-01-04 23:08:41,109][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:41,109][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:42,746][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:42,747][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:42,909][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:42,910][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:42,910][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:42,910][HYDRA] Inference time: 0.16\n",
      "[2023-01-04 23:08:42,911][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:42,911][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:42,911][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:42,911][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:42,916][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:44,080][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:44,083][HYDRA] Steps: 20, F1: 22.2, Max F1: 22.2, Time: 2.97\n",
      "[2023-01-04 23:08:44,084][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.89 mins\n",
      "[2023-01-04 23:08:44,084][HYDRA] Steps done 20\n",
      "[2023-01-04 23:08:44,084][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:44,084][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:45,703][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:45,704][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:45,795][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:45,796][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:45,797][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:45,797][HYDRA] Inference time: 0.09\n",
      "[2023-01-04 23:08:45,797][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:45,797][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:45,797][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:45,797][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:45,802][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:47,009][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:47,012][HYDRA] Steps: 30, F1: 22.2, Max F1: 22.2, Time: 2.93\n",
      "[2023-01-04 23:08:47,013][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.84 mins\n",
      "[2023-01-04 23:08:47,013][HYDRA] Steps done 30\n",
      "[2023-01-04 23:08:47,013][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:47,013][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:48,657][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:48,658][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:48,827][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:48,829][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:48,829][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:48,829][HYDRA] Inference time: 0.17\n",
      "[2023-01-04 23:08:48,829][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:48,829][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:48,829][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:48,829][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:48,834][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:50,046][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:50,049][HYDRA] Steps: 40, F1: 22.2, Max F1: 22.2, Time: 3.04\n",
      "[2023-01-04 23:08:50,049][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.79 mins\n",
      "[2023-01-04 23:08:50,049][HYDRA] Steps done 40\n",
      "[2023-01-04 23:08:50,049][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:50,049][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:51,699][HYDRA] cur_document:s59310199_findings_0, loss:15.445, Max mem 2.6 GB\n",
      "[2023-01-04 23:08:51,700][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:51,702][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:51,831][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:51,832][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:51,832][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:51,833][HYDRA] Inference time: 0.13\n",
      "[2023-01-04 23:08:51,833][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:51,833][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:51,833][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:51,833][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:51,838][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:53,055][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:53,058][HYDRA] Steps: 50, F1: 22.2, Max F1: 22.2, Time: 3.01\n",
      "[2023-01-04 23:08:53,058][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.74 mins\n",
      "[2023-01-04 23:08:53,058][HYDRA] Steps done 50\n",
      "[2023-01-04 23:08:53,058][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:53,058][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:54,703][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:54,704][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:54,829][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:54,831][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:54,831][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:54,831][HYDRA] Inference time: 0.12\n",
      "[2023-01-04 23:08:54,831][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:54,831][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:54,831][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:54,831][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:54,836][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:56,046][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:56,050][HYDRA] Steps: 60, F1: 22.2, Max F1: 22.2, Time: 2.99\n",
      "[2023-01-04 23:08:56,050][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.69 mins\n",
      "[2023-01-04 23:08:56,050][HYDRA] Steps done 60\n",
      "[2023-01-04 23:08:56,050][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:56,050][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:08:57,760][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:08:57,761][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:08:57,894][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:08:57,895][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:08:57,895][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:08:57,896][HYDRA] Inference time: 0.13\n",
      "[2023-01-04 23:08:57,896][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:08:57,896][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:08:57,896][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:08:57,896][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:08:57,901][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:08:59,130][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:08:59,133][HYDRA] Steps: 70, F1: 22.2, Max F1: 22.2, Time: 3.08\n",
      "[2023-01-04 23:08:59,133][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.64 mins\n",
      "[2023-01-04 23:08:59,133][HYDRA] Steps done 70\n",
      "[2023-01-04 23:08:59,133][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:08:59,133][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:09:00,838][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:09:00,840][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:09:01,009][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:09:01,010][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:09:01,010][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:09:01,011][HYDRA] Inference time: 0.17\n",
      "[2023-01-04 23:09:01,011][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:09:01,011][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:09:01,011][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:09:01,011][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:09:01,016][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:09:02,224][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:09:02,227][HYDRA] Steps: 80, F1: 22.2, Max F1: 22.2, Time: 3.09\n",
      "[2023-01-04 23:09:02,227][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.59 mins\n",
      "[2023-01-04 23:09:02,227][HYDRA] Steps done 80\n",
      "[2023-01-04 23:09:02,227][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:09:02,228][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:09:03,358][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:09:03,359][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:09:03,450][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:09:03,452][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:09:03,452][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:09:03,452][HYDRA] Inference time: 0.09\n",
      "[2023-01-04 23:09:03,452][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:09:03,452][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:09:03,452][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:09:03,452][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:09:03,457][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:09:04,686][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:09:04,689][HYDRA] Steps: 90, F1: 22.2, Max F1: 22.2, Time: 2.46\n",
      "[2023-01-04 23:09:04,689][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.55 mins\n",
      "[2023-01-04 23:09:04,689][HYDRA] Steps done 90\n",
      "[2023-01-04 23:09:04,689][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:09:04,689][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:09:05,856][HYDRA] cur_document:s58180184_findings_0, loss:51.011, Max mem 2.7 GB\n",
      "[2023-01-04 23:09:05,858][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:09:05,859][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:09:05,949][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:09:05,951][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:09:05,951][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:09:05,951][HYDRA] Inference time: 0.09\n",
      "[2023-01-04 23:09:05,951][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:09:05,951][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:09:05,951][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:09:05,951][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:09:05,956][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:09:07,163][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:09:07,166][HYDRA] Steps: 100, F1: 22.2, Max F1: 22.2, Time: 2.48\n",
      "[2023-01-04 23:09:07,166][HYDRA] Average eval time: 0.05 mins, Remaining time: 899.51 mins\n",
      "[2023-01-04 23:09:07,166][HYDRA] Steps done 100\n",
      "[2023-01-04 23:09:07,166][HYDRA] mimic_manual_500_unsplit: Subsampled 10\n",
      "[2023-01-04 23:09:07,166][HYDRA] Per epoch training steps: 10\n",
      "[2023-01-04 23:09:08,342][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:09:08,344][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:09:08,433][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:09:08,434][HYDRA] Oracle F-score: 0.000\n",
      "[2023-01-04 23:09:08,434][HYDRA] /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.log.jsonl\n",
      "[2023-01-04 23:09:08,435][HYDRA] Inference time: 0.09\n",
      "[2023-01-04 23:09:08,435][HYDRA] Max inference memory: 2.2 GB\n",
      "[2023-01-04 23:09:08,435][HYDRA] {'mimic_manual_500_unsplit': 22.2}\n",
      "[2023-01-04 23:09:08,435][HYDRA] F1: 22.2, Max F1: 22.2\n",
      "[2023-01-04 23:09:08,435][HYDRA] Save model to /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth, last_checkpoint:[True]\n",
      "[2023-01-04 23:09:08,440][HYDRA] Save the optimizer and scheduler states\n",
      "[2023-01-04 23:09:09,647][HYDRA] Model saved at: /scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth\n",
      "[2023-01-04 23:09:09,650][HYDRA] Steps: 110, F1: 22.2, Max F1: 22.2, Time: 2.48\n",
      "[2023-01-04 23:09:09,650][HYDRA] Triggered train_info[\"num_stuck_evals\"] (10) >= config.trainer.patience (10)\n",
      "[2023-01-04 23:09:09,650][HYDRA] Stop training\n",
      "[2023-01-04 23:09:09,650][HYDRA] Triggered train_info[\"num_stuck_evals\"] (10) >= config.trainer.patience (10)\n",
      "[2023-01-04 23:09:09,650][HYDRA] Stop training\n",
      "[2023-01-04 23:09:09,651][HYDRA] Perform final evaluation (Initial for evaluation)\n",
      "[2023-01-04 23:09:09,651][HYDRA] Step 1 - Initialize best model for evaluation\n",
      "[2023-01-04 23:09:09,651][HYDRA] Load checkpoint from best_model_path:/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth\n",
      "[2023-01-04 23:09:09,651][HYDRA] Original self.config:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': True, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}, 'datasets': {'mimic_manual_500_unsplit': {'name': 'mimic_manual_500_unsplit', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 10, 'num_dev_docs': 1, 'num_test_docs': 156, 'has_conll': True, 'singleton_file': None}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 54000, 'job_id': 904102, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:09:09,732][HYDRA] config=checkpoint[\"config\"]:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': True, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}, 'datasets': {'mimic_manual_500_unsplit': {'name': 'mimic_manual_500_unsplit', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 10, 'num_dev_docs': 1, 'num_test_docs': 156, 'has_conll': True, 'singleton_file': None}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 54000, 'job_id': 904102, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:09:09,733][HYDRA] Use the pre-downloaded decoder (from hugging face).\n",
      "[2023-01-04 23:09:09,733][HYDRA] self.config.model.doc_encoder.transformer{'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}\n",
      "[2023-01-04 23:09:09,735][HYDRA] train_info:{'val_perf': 22.2, 'global_steps': 10, 'num_stuck_evals': 0, 'peak_memory': 0.0, 'max_mem': 0.0}\n",
      "[2023-01-04 23:09:09,735][HYDRA] New config:{'metrics': ['MUC', 'Bcub', 'CEAFE'], 'keep_singletons': False, 'seed': 45, 'train': True, 'use_wandb': False, 'override_encoder': True, 'override_memory': False, 'copy_from_pretrained_model': True, 'continue_training': False, 'paths': {'resource_dir': '${infra.project_dir}/coref_resources', 'base_data_dir': '${paths.resource_dir}/data', 'conll_scorer': '${paths.resource_dir}/reference-coreference-scorers/scorer.pl', 'base_model_dir': '${infra.project_dir}/models', 'model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2', 'best_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best', 'model_filename': 'model.pth', 'model_name': 'model_904_10_2', 'model_name_prefix': 'coref_', 'model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/model.pth', 'best_model_path': '/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/best/model.pth', 'doc_encoder_dirname': 'doc_encoder', 'pretrain_model_dir': '/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best'}, 'datasets': {'mimic_manual_500_unsplit': {'name': 'mimic_manual_500_unsplit', 'cluster_threshold': 2, 'canonical_cluster_threshold': 2, 'targeted_eval': False, 'num_train_docs': 10, 'num_dev_docs': 1, 'num_test_docs': 156, 'has_conll': True, 'singleton_file': None}}, 'model': {'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}, 'optimizer': {'init_lr': 0.0003, 'fine_tune_lr': 1e-05, 'max_gradient_norm': 1.0, 'lr_decay': 'linear'}, 'trainer': {'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}, 'infra': {'is_local': False, 'job_time': 54000, 'job_id': 904102, 'project_dir': '/scratch/c.c21051562/workspace/fast-coref', 'work_dir': '${project_dir}/src/'}}\n",
      "[2023-01-04 23:09:09,735][HYDRA] Load the EntityRankingModel\n",
      "[2023-01-04 23:09:09,735][HYDRA] config.model:{'doc_encoder': {'transformer': {'name': 'longformer', 'model_size': 'large', 'model_str': '/scratch/c.c21051562/workspace/fast-coref/models/longformer_coreference_joint', 'max_encoder_segment_len': 4096, 'max_segment_len': 4096}, 'chunking': 'independent', 'finetune': False, 'add_speaker_tokens': True, 'speaker_start': '[SPEAKER_START]', 'speaker_end': '[SPEAKER_END]'}, 'memory': {'mem_type': {'name': 'unbounded', 'max_ents': None, 'eval_max_ents': None}, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'sim_func': 'hadamard', 'entity_rep': 'wt_avg', 'num_feats': 2}, 'mention_params': {'max_span_width': 20, 'ment_emb': 'attn', 'use_gold_ments': False, 'use_topk': False, 'top_span_ratio': 0.4, 'emb_size': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'ment_emb_to_size_factor': {'attn': 3, 'endpoint': 2, 'max': 1}}, 'metadata_params': {'use_genre_feature': False, 'default_genre': 'nw', 'genres': ['bc', 'bn', 'mz', 'nw', 'pt', 'tc', 'wb']}}\n",
      "[2023-01-04 23:09:09,735][HYDRA] config.trainer:{'dropout_rate': 0.3, 'label_smoothing_wt': 0.1, 'ment_loss': 'all', 'normalize_loss': False, 'max_evals': 100, 'to_save_model': True, 'log_frequency': 50, 'patience': 10, 'eval_per_k_steps': 10, 'num_training_steps': 1000, 'max_training_segments': 1}\n",
      "[2023-01-04 23:09:18,532][HYDRA] Step 2 - Load Data - Data processing choices such as tokenizer will depend on the model\n",
      "[2023-01-04 23:09:18,538][HYDRA] --self.config.paths.base_data_dir:/scratch/c.c21051562/workspace/fast-coref/coref_resources/data\n",
      "[2023-01-04 23:09:18,538][HYDRA] Data directory: /scratch/c.c21051562/workspace/fast-coref/coref_resources/data/mimic_manual_500_unsplit/longformer\n",
      "[2023-01-04 23:09:18,609][HYDRA] Number of training steps: 1000\n",
      "[2023-01-04 23:09:18,610][HYDRA] Step 3 - Perform evaluation\n",
      "[2023-01-04 23:09:18,612][HYDRA] Max training memory: 0.0 GB\n",
      "[2023-01-04 23:09:18,612][HYDRA] Validation performance: 22.2\n",
      "[2023-01-04 23:09:18,612][HYDRA] \n",
      "\n",
      "[2023-01-04 23:09:18,612][HYDRA] Dev\n",
      "[2023-01-04 23:09:18,612][HYDRA] Dataset: mimic_manual_500_unsplit\n",
      "\n",
      "[2023-01-04 23:09:18,612][HYDRA] Dataset: mimic_manual_500_unsplit, Cluster Threshold: 2\n",
      "[2023-01-04 23:09:18,613][HYDRA] Evaluating on 1 examples\n",
      "[2023-01-04 23:09:18,705][HYDRA] F-score: 22.2 , MUC: 0.0, Bcub: 33.3, CEAFE: 33.3\n",
      "[2023-01-04 23:09:18,706][HYDRA] \n",
      "\n",
      "Using CoNLL scorer\n",
      "/scratch/c.c21051562/workspace/fast-coref/coref_resources/data/mimic_manual_500_unsplit/conll/dev.conll\n",
      "/scratch/c.c21051562/workspace/fast-coref/models/coref_model_904_10_2/mimic_manual_500_unsplit/dev.conll\n",
      "/scratch/c.c21051562/workspace/fast-coref/coref_resources/reference-coreference-scorers/scorer.pl\n",
      "Error executing job with overrides: ['infra.job_time=54000', 'infra=arcca', 'experiment=arcca_exp_9', 'infra.job_id=904_10_2', 'paths.model_name=model_904_10_2', 'trainer.eval_per_k_steps=10', 'datasets.mimic_manual_500_unsplit.num_train_docs=10', 'datasets.mimic_manual_500_unsplit.num_dev_docs=1', 'copy_from_pretrained_model=True', 'paths.pretrain_model_dir=/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best']\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/main.py\", line 164, in main\n",
      "    Experiment(config)\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/experiment.py\", line 79, in __init__\n",
      "    self.perform_final_eval()\n",
      "  File \"/home/c.c21051562/.conda/envs/fast_coref/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/experiment.py\", line 634, in perform_final_eval\n",
      "    result_dict = coref_evaluation(\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/utils_evaluate.py\", line 378, in coref_evaluation\n",
      "    return full_coref_evaluation(\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/utils_evaluate.py\", line 183, in full_coref_evaluation\n",
      "    conll_results = evaluate_conll(\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/coref_utils/conll.py\", line 118, in evaluate_conll\n",
      "    output_conll(gold_file, prediction_file, predictions, subtoken_maps)\n",
      "  File \"/scratch/c.c21051562/workspace/fast-coref/src/coref_utils/conll.py\", line 57, in output_conll\n",
      "    start_map, end_map, word_map = prediction_map[doc_key]\n",
      "KeyError: 's58956439_impression_0'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "# !HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\\n",
    "# python3 /scratch/c.c21051562/workspace/fast-coref/src/main.py \\\n",
    "# infra=arcca experiment=arcca_exp_9 \\\n",
    "# paths.model_name=model_901_2 \\\n",
    "# infra.job_time=54000 infra.job_id=901_2 \\\n",
    "# copy_from_pretrained_model=True \\\n",
    "# paths.pretrain_model_dir=\"/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best\"\n",
    "\n",
    "!HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\\n",
    "python3 /scratch/c.c21051562/workspace/fast-coref/src/main.py \\\n",
    "infra.job_time=54000 \\\n",
    "infra=arcca experiment=arcca_exp_9 \\\n",
    "infra.job_id=904_10_2 \\\n",
    "paths.model_name=model_904_10_2 \\\n",
    "trainer.eval_per_k_steps=460 \\\n",
    "datasets.mimic_manual_500_unsplit.num_train_docs=460 \\\n",
    "datasets.mimic_manual_500_unsplit.num_dev_docs=5 \\\n",
    "copy_from_pretrained_model=True \\\n",
    "paths.pretrain_model_dir=\"/scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_301/best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae89c9f-2ff5-4376-8b17-110e976f7f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-04 23:09:19'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c43a60-903b-44c6-b72e-6d5e754b227f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fast_coref]",
   "language": "python",
   "name": "conda-env-.conda-fast_coref-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
